% Shared Control
\chapter{Shared Control with Remote Human Pilot and Output Feedback}  \label{ch:mimo_shared_ctrl}
In this chapter, a shared control framework is proposed to address the problem stated in Chapter \ref{sec:mimo_problem}. Whereas the shared control framework proposed in Chapter \ref{ch:siso_shared_ctrl} was applicable to SISO plants with the full plant state measured and a human pilot on-board, the shared control framework to be presented here applies to MIMO plants where the full plant state is not measured directly, and humans operate remotely. As in Chapter \ref{ch:siso_shared_ctrl}, the shared control framework is designed so as to combine the merits of both adaptive control algorithms and humans. 

It is assumed that adaptive autopilots and complementary higher-level motion planning algorithms allow for continuous autonomous operation of the vehicle in the presence of parametric uncertainties $\Theta_p$, $\Lambda_p$, and $\Theta_1$ in (\ref{eq:plant_dynamics}) and (\ref{eq:first_order_act}). Remote human operators monitor the performance of the vehicles and are trained and able to remotely pilot the vehicle in case of autopilot failure. The remote piloting of the vehicles, however, is a daunting task due to communication delays and a weakened understanding of the vehicle dynamics, state, and environment, due to the remote nature of the task. Our shared anomaly response tasks the human operator with providing key inputs based on higher-level perception of the anomaly, but delegates the low-level regulation and command tracking tasks to adaptive control algorithms which make use of these inputs. In Section \ref{subsec:sc_adaptive}, we describe two adaptive autopilot designs which in combination with the human operator whose precise role is described subsequently in Section \ref{subsec:sc_human}, will solve the problem which was presented in Section \ref{sec:mimo_problem}. The overall shared control architecture is summarized in Section \ref{subsec:sc_overall}.

% TODO possible to make block diagram for OF/MIMO?
\section{Adaptive Output-Feedback Control}\label{subsec:sc_adaptive}
In this section, an autonomous controller is designed so that plant outputs $z_p(t)$ in (\ref{eq:plant_dynamics}) will track prescribed commands $z_{cmd}(t)$. The shared control framework will make use of separate adaptive control designs for the plant (\ref{eq:plant_dynamics}) in combination with actuator dynamics (\ref{eq:first_order_act}) and (\ref{eq:second_order_act}). The control design accommodating first-order actuators is denoted the \textit{nominal} adaptive control design, and excluding exceptional failures, is the controller in use by the autopilot. The control design accommodating second-order actuators is a predefined \textit{recovery} adaptive controller, whose use case will be defined more fully in Section \ref{subsec:sc_human}. To achieve the control goals stated in Section \ref{ch:problem}, control design consists of
\begin{enumerate}[label=(\roman*)]
	\item baseline control design using the robust servomechanism linear quadratic regulator method (RSLQR);
	\item adaptive output-feedback augmentation for parametric uncertainties in the plant.
\end{enumerate}

Control design in each case uses an augmented linear plant formulation, where the plant (\ref{eq:plant_dynamics}) is extended with the actuator dynamics -- either (\ref{eq:first_order_act}) or (\ref{eq:second_order_act}) -- as well as integrated tracking errors 
\begin{equation}
	e_z^{\mathcal{I}}(t) = \int_0^{t} \big( z_p(\tau) - z_{cmd}(\tau)\big) d\tau.
\end{equation}

The augmented plant model with state vector $x = \begin{bmatrix} x_p^T & x_{act}^T & (e_z^{\mathcal{I}})^T\end{bmatrix}^T$ can written compactly as
\begin{equation}
\begin{array}{c}
\dot{x}= \left(A+B_{1}\Psi_{1}^{T}+B_{r}\Psi_{r}^{T}\right) x+B_{r}\Lambda u+B_{z}z_{cmd}\\
y=Cx,\qquad z=C_{z}x
\end{array} \label{eq:augmented_plant}
\end{equation}
where $x\in\mathbb{R}^{n}$, $u\in\mathbb{R}^{m}$, $y\in\mathbb{R}^{p}$ are redefined states, inputs and outputs, respectively. This plant has unknown matrices $\Psi_1$, $\Psi_r$, and $\Lambda$, which contain plant uncertainties ($\Theta_p$), actuator uncertainties ($\Theta_i$ in (\ref{eq:first_order_act}) and (\ref{eq:second_order_act})), and control effectiveness ($\Lambda_p$), respectively. Note that the uncertainty has been reparameterized for notational simplicity when analyzing the augmented plant form. The exact forms of $B_r$ and $\Psi_r$ depend on whether the actuators are first-order (\ref{eq:first_order_act}) or second-order (\ref{eq:second_order_act}), and the subscript $r$ indicates the relative degree of the augmented plant. It is noted that the augmented plant model which arises from the inclusion of actuator model (\ref{eq:first_order_act}) in the plant (\ref{eq:plant_dynamics}) has relative degree two, while the augmented plant model associated with the inclusion of actuator model (\ref{eq:second_order_act}) has relative degree three. 

For adaptive control design, closed-loop reference models \cite{gibson2013adaptive} are designed as
\begin{equation}
\dot{x}_m = A_m x_m + B_z z_{cmd} + L e_y + \mathcal{F}_r(t), \quad y_m = C x_m \label{eq:crm_mimo}
\end{equation}
where $e_y = y - y_m$, $A_m = A - B_r K_{\textrm{LQR}}^T$ with $K_{\textrm{LQR}}\in\mathbb{R}^{n\times m}$ is a baseline feedback control gain designed for the system without uncertainty using RSLQR, as described by \cite{lavretsky2013robust}. $L$ is a Luenberger-like feedback gain, and $\mathcal{F}_r(t)$ is a function used when $r \geq 2$ to recover stability properties in the presence of uncertainty. Note that $u^*(t) = - K_{\textrm{LQR}}^T x(t)$ is the control policy which minimizes the infinite-horizon quadratic cost function
\begin{equation}
J = \int_0^\infty \big[ x^T Q_{\textrm{LQR}} x + u^T R_{\textrm{LQR}}	u\big] dt
\end{equation}
where $Q \geq 0$ and $R > 0$, and the system dynamics are assumed to be $\dot x = A x + B_r u$.

In what follows, we define a \textit{nominal} adaptive autopilot for the plant (\ref{eq:augmented_plant}) as one that successfully accommodates actuator dynamics in the form of (\ref{eq:first_order_act}) and unknown $\Theta_p$, $\Theta_1$, and $\Lambda_p$. We define a \textit{recovery} adaptive autopilot to be one that is successful in accommodating actuator dynamics (\ref{eq:second_order_act}), i.e., when it is known that the relative degree is three, with uncertain parameters $\Theta_p$, $\Theta_1$, $\Theta_2$, and $\Lambda_p$. We restrict our attention in this chapter to augmented plant models (\ref{eq:augmented_plant}) which are square (i.e. the number of inputs, $m$, is equal to the number of outputs, $p$). For details of closed-loop stability guarantees with the nominal and recovery adaptive controllers, readers are referred to \cite{qu2016adaptive} and \cite{qu2016phd}, respectively.
 
\subsection{Nominal Adaptive Controller}
%Relative degree two MIMO adaptive control.
% need a11, a10, B_1^a, Cbar, S, Rinv, epsilon, L, two tuner laws, u, F
The control design for the plant with first-order actuator dynamics will be summarized by describing the CRM residual gain matrix $L$, function $\mathcal{F}_2(t)$, control law $u(t)$, and parameter adaptation. Note that $B_2$ represents $B_r$ from (\ref{eq:augmented_plant}) for this relative degree two plant. 

The feedback matrix $L$ is designed as follows. We define the ``relative degree one input path''
\begin{equation}
B_1^a = \alpha_0 B_2 + \alpha_1 A B_2 \label{eq:rd2-b1a}
\end{equation}
where $\alpha_i > 0$ are free design parameters. We then define
\begin{align}
S &= (C B_1^a)^T \label{eq:S}\\	\overline{C} & = S C\\ R^{-1} &= (\overline{C} B_1^a)^{-1} \big[ \overline{C} A B_1^a + (\overline{C} A B_1^a)^T\big] (\overline{C} B_1^a)^{-1} + \epsilon I \\ L & = B_1^a R^{-1} S \label{eq:L}
\end{align}
where the scalar parameter $\epsilon > 0$ \cite[Eq. 30]{qu2015adaptive} is chosen to be large enough in magnitude to guarantee stability of the adaptive system. 

The function $\mathcal{F}_2(t)$ makes use of scaled output error signal
\begin{equation}
	e_{sy}(t) = R^{-1} S e_y(t) \label{eq:esy}
\end{equation}
and a filtered version of this signal, denoted $\overline{e}_{sy}(t)$, given in the form of a differential equation as
\begin{equation}
(\alpha_0 + \alpha_1 \frac{d}{dt}) \big\{ \overline{e}_{sy}(t) \big\} = \alpha_1 e_{sy}(t). \label{eq:e_sy_bar}
\end{equation}
It is worth noting that this filtered signal can be represented in the Laplace $s$-domain as
\begin{equation*}
	\overline{E}_{sy}(s) = \frac{\alpha_1}{\alpha_1 s + \alpha_0} E_{sy}(s).
\end{equation*}
The function $\mathcal{F}_2(t)$ is then defined as
\begin{equation}
\mathcal{F}_2(t) = B_2 (\alpha_0 + \alpha_1 \frac{d}{dt})\big\{ \hat{\Psi}_m^T (t) \bar{e}_{sy}(t) \big\} \label{eq:F2}
\end{equation}
where $\hat{\Psi}_m(t)$ is a matrix of adaptive parameters. Similar to (\ref{eq:e_sy_bar}), we define filtered reference model state, $\overline{x}_m(t)$, with the differential equation
\begin{equation}
(\alpha_0 + \alpha_1 \frac{d}{dt}) \big\{ \overline{x}_{m}(t) \big\} = \alpha_1 x_{m}(t)\label{eq:xm_bar}
\end{equation}
and the equivalent frequency domain representation
\begin{equation}
	\overline{X}_{m}(s) = \frac{\alpha_1}{\alpha_1 s + \alpha_0} X_{m}(s).
\end{equation}

We define a regressor vector of known signals as
\begin{equation}
\mathcal{X}(t) = \big[ (K_{\textrm{LQR}}^T \overline{x}_m)^T,\quad x_m^T,\quad \overline{x}_m^T \big]^T.
\end{equation}

The control law, $u(t)$, which defines the input to the plant (\ref{eq:augmented_plant}), is then given by
\begin{equation}
u(t) = - (\alpha_0 + \alpha_1 \frac{d}{dt}) \big \{ \hat{\Psi}_{\Lambda}^T (t) \mathcal{X}(t) \big\} \label{eq:u_rd2}	
\end{equation}
where $\hat{\Psi}_{\Lambda}(t)$ is a matrix of adaptive parameters. The laws for adaptation of parameter matrices $\hat{\Psi}_m(t)$ and $\hat{\Psi}_{\Lambda}(t)$ are given by
\begin{equation}
\begin{aligned}
	\dot{\hat{\Psi}}_m(t) &= \Gamma_{m} \overline{e}_{sy}(t) e_y^T(t) S^T \\
	\dot{\hat{\Psi}}_{\Lambda}(t) &= -\Gamma_{\Lambda} \mathcal{X}(t) e_y^T (t) S^T
\end{aligned} \label{eq:rd2-adaptation}
\end{equation}
with diagonal adaptation gains $\Gamma_{m}, \;\Gamma_{\Lambda} > 0$. We note that the derivatives of the adaptive parameters, computed in (\ref{eq:rd2-adaptation}), are used to implement (\ref{eq:F2}) and (\ref{eq:u_rd2}) with the product rule of differentiation. The expanded form of the control law, following the product rule of differentiation, is given by
\begin{equation}
u(t) = - \alpha_0 \hat{\Psi}_{\Lambda}^T (t) \mathcal{X}(t) - \alpha_1 \dot{\hat{\Psi}}_{\Lambda}^T (t) \mathcal{X}(t) - \alpha_1 \hat{\Psi}_{\Lambda}^T (t) \dot{\mathcal{X}}(t).
\end{equation}
For the plant (\ref{eq:plant_dynamics}) with first-order actuator model (\ref{eq:first_order_act}), an adaptive controller designed with reference model given by (\ref{eq:crm_mimo}), control input given by (\ref{eq:u_rd2}), and parameter adaptation given by (\ref{eq:rd2-adaptation}), asymptotic convergence of $e_y(t)$ to 0 is achieved.

\subsection{Recovery Adaptive Controller}
Control design for the plant (\ref{eq:plant_dynamics}) with the second-order actuator model (\ref{eq:second_order_act}) is similar to that described above, but requires modifications to ensure strict positive realness of the transfer matrix of the model-following error dynamics. 

The definition of $L$ is modified by replacing $B_1^a$ in (\ref{eq:rd2-b1a}) with
\begin{equation}
B_1^a = \alpha_0 B_3 + \alpha_1 A B_3 + \alpha_2 A^2 B_3 \label{eq:rd3-b1a}
\end{equation}
and proceeding with (\ref{eq:S})--(\ref{eq:L}). A definition for $\epsilon>0$ in this case can be found in \cite{qu2016phd}. To simplify notation, the operator $\Pi \{\cdot \}$ is defined as
\begin{equation}
\Pi \{ \cdot \} = \big( \alpha_0 + \alpha_1 \frac{d}{dt} + \alpha_2 \frac{d^2}{dt^2} \big) \{ \cdot \}.
\end{equation}
%which is equivalently represented in the Laplace $s$-domain by
%\begin{equation}
%\Pi (s) = \alpha_2 s^2 + \alpha_1 s + \alpha_0.	
%\end{equation}

The function $\mathcal{F}_3(t)$ utilizes several filtered output error vectors, denoted $\overline{e}_{sy}^{[1]}(t)$, $\overline{e}_{sy}^{[2]}(t)$, and $\overline{e}_{sy}^{[1][2]}(t)$, defined by the differential equations
\begin{equation}
\begin{aligned} 
	\Pi \big \{ \overline{e}_{sy}^{[1]}(t) \big \} & = (\alpha_1 + \alpha_2 \frac{d}{dt}) \big \{ e_{sy}(t) \big \} \\
	\Pi \big \{ \overline{e}_{sy}^{[2]}(t) \big \} & = \alpha_2 e_{sy}(t) \\
	\Pi \big \{ \overline{e}_{sy}^{[1][2]}(t) \big \} & = (\alpha_2 \frac{d}{dt}) \big \{ \hat{\phi}_1^T(t) \bar{e}_{sy}^{[1]}(t) \big \}
\end{aligned} \label{eq:esy_rd3}
\end{equation}
where $e_{sy}(t)$ was defined in (\ref{eq:esy}), $\hat{\phi}_1(t)$ is a vector of adaptive parameters, and coefficients $\alpha_i > 0$ are free design parameters. The equivalent frequency domain representations of these filtered signals are given by
\begin{equation}
\begin{gathered}
	\overline{E}_{sy}^{[1]} = \frac{\alpha_2 s + \alpha_1}{\alpha_2 s^2 + \alpha_1 s + \alpha_0} E_{sy}, \qquad \overline{E}_{sy}^{[1]} = \frac{\alpha_2}{\alpha_2 s^2 + \alpha_1 s + \alpha_0} E_{sy} \\
	\overline{E}_{sy}^{[1][2]} = \frac{\alpha_2 s}{\alpha_2 s^2 + \alpha_1 s + \alpha_0} \big( \hat{\phi}_1^T E_{sy}^{[1]} \big)
	\end{gathered}
\end{equation}
We define a scaled, integrated measurement output error, 
\begin{equation}
e_{y}^{\mathcal{I}}(t) = \int_0^{t} L\big (y(\tau) - y_m(\tau)\big) d\tau
\end{equation}
which is used to define filtered error signals $\overline{e}_{\mathcal{I}y}^{[1]} (t)$ and $\overline{e}_{\mathcal{I}y}^{[1][2]} (t)$, given by
\begin{equation}
\begin{aligned}
	\Pi \big \{  \overline{e}_{\mathcal{I}y}^{[1]} (t) \big \} &= (\alpha_1 \frac{d}{dt} + \alpha_2 \frac{d^2}{dt^2}) \big \{ \hat{\Phi}_1^T (t) e_{y}^{\mathcal{I}}(t) \big \} \\
	\Pi \big \{  \overline{e}_{\mathcal{I}y}^{[1][2]} (t) \big \} &= (\alpha_2 \frac{d}{dt}) \big \{ \hat{\Lambda}^T(t) \overline{e}_{\mathcal{I}y}^{[1]} (t) \big \}
\end{aligned} \label{eq:eIy_rd3}
\end{equation}
where $\hat{\Phi}_1(t)$ and $\hat{\Lambda}(t)$ are matrices of adaptive parameters. We define operators
\begin{equation}
\begin{aligned}
	f_a \{ \cdot \} &= \big(\alpha_0 \alpha_2 B_3 + (\alpha_1 B_3 + \alpha_2 A B_3)\frac{d}{dt} \big) \{ \cdot \} \\
	f_b \{ \cdot \} &= \alpha_2 B_3 \Pi \{ \cdot \}
\end{aligned}
\end{equation}
and use these to fully define
\begin{multline}
	\mathcal{F}_3(t) = f_a \big \{ \hat{\phi}_1^T(t) \overline{e}_{sy}^{[1]}(t) - \hat{\Lambda}^T(t) \overline{e}_{\mathcal{I}y}^{[1]} (t) \big \} \\
	+ f_b \big \{ \hat{\phi}_1^T(t) \big[\overline{e}_{sy}^{[1][2]}(t) -  \overline{e}_{\mathcal{I}y}^{[1][2]} (t) \big ] + \hat{\phi}_2^T (t) \overline{e}_{sy}^{[2]}(t) \big \} \label{eq:F3}
\end{multline}
where $\hat{\phi}_2(t)$ is an additional vector of adaptive parameters. The control input synthesized by the recovery adaptive controller, as well as parameter adaptation, make use of filtered reference model states $\overline{x}_m^{[1]}$ and $\overline{x}_m^{[2]}$, given by the differential equations
\begin{equation}
\begin{aligned}
	\Pi \big \{  \overline{x}_{m}^{[1]} (t) \big \} &= (\alpha_1 + \alpha_2 \frac{d}{dt}) \big \{ x_m (t) \big \} \\
	\Pi \big \{  \overline{x}_{m}^{[2]}(t) \big \} &= \alpha_2 x_m (t).
\end{aligned}	
\end{equation}

Variable $\overline{v}_m(t)$ is introduced, with artificial time derivatives, such that
\begin{equation}
\begin{gathered}
	\overline{v}_m = x_m, \quad \frac{d }{dt}\{ \overline{v}_m \} = A x_m + B_z z_{cmd} \\
	\frac{d^2}{dt^2} \{ \overline{v}_m \} = A^2 x_m + A B_z z_{cmd} + B_z \frac{dz_{cmd}}{dt} - A L e_y.
\end{gathered}
\end{equation}
The regressor vector $\mathcal{X}(t)$, similar to that used by the nominal adaptive controller, is defined as
\begin{equation}
\mathcal{X}(t) = \big[ (K_{\textrm{LQR}}^T \overline{x}_m^{[2]})^T,\quad \overline{v}_m^T,\quad \overline{x}_m^{[1]T},\quad \overline{x}_m^{[2]T} \big]^T.
\end{equation}
The control law $u(t)$ for the recovery adaptive controller is
\begin{equation}
\begin{aligned}
	u (t) = -&\Pi \big \{ \hat{\Psi}^T(t) \mathcal{X}(t) \big \} \\ - & (\alpha_1 \frac{d}{dt} + \alpha_2 \frac{d^2}{dt^2}) \big \{ \hat{\Phi}_1^T(t) \big \} e_y^\mathcal{I} (t) 
\end{aligned} \label{eq:u_rd3}
\end{equation}
where 
\begin{equation}
\hat{\Psi}(t) = \big[ \hat{\Upsilon}^T(t),\quad \hat{\Phi}_1^T(t),\quad \hat{\Phi}_2^T(t),\quad \hat{\Phi}_3^T(t) \big]^T 
\end{equation}
is a matrix of adaptive parameters. 

In this controller, the laws for parameter adaptation use second-order tuners as in \cite{qu2016phd}. This differs from the first-order adaptive laws used in the nominal adaptive control design, and in the adaptive controllers defined in Chapter \ref{ch:siso_shared_ctrl}. We first define a regressor vector $\nu(t)$ of filtered error signals
\begin{equation}
	\nu(t) = \begin{bmatrix}
		(\overline{e}_{\mathcal{I}y}^{[1][2]} - \overline{e}_{sy}^{[1]} - \overline{e}_{sy}^{[1][2]})^T, & \quad (-\overline{e}_{sy}^{[2]})^T, & \quad (\overline{e}_{\mathcal{I}y}^{[1]})^T
	\end{bmatrix}^T
\end{equation}
and associated matrix of adaptive parameters
\begin{equation}
\hat{\Theta}(t) = \big[ \hat{\phi}_1^T(t),\quad \hat{\phi}_2^T(t),\quad \hat{\Lambda}^T(t) \big]^T.
\end{equation}

Inputs to the second-order tuners are calculated by integrating
\begin{equation}
\begin{aligned}
\dot{\hat{\Psi}}'(t) &= \Gamma_{\Psi} \mathcal{X} e_y^T S^T \text{sgn}(\Lambda) \\
\dot{\hat{\Theta}}'(t) &= -\Gamma_{\Theta} \nu e_y^T S^T
\end{aligned} \label{eq:rd3-adaptation-start}
\end{equation}
where $\Gamma_{\Psi}, \Gamma_{\Theta} > 0$ are diagonal adaptation gains. 

The desired matrices of adaptive parameters are outputs of the tuners
\begin{equation}
\begin{aligned}
	\dot{X}_{\hat{\Psi}}(t) &= \big( A_T X_{\hat{\Psi}} + B_T (\hat{\Psi}'(t))^T \big) g(\mathcal{X}, \mu_{\mathcal{X}}) \\
	\hat{\Psi}(t) &= (C_T X_{\hat{\Psi}})^T \\
	\dot{X}_{\hat{\Theta}}(t) &= \big( A_T X_{\hat{\Theta}} + B_T (\hat{\Theta}'(t))^T \big) g(\nu, \mu_{\nu}) \\
	\hat{\Theta}(t) &= (C_T X_{\hat{\Theta}})^T
\end{aligned}	
\end{equation}
where
\begin{equation}
g(\mathbf{x}, \mu) = 1 + \mu \mathbf{x}^T \mathbf{x}	
\end{equation}
is a time-varying gain with scalar gain $\mu$ described in \cite{qu2016phd}. $A_T \in \mathbb{R}^{2m \times 2m}$, $B_T \in \mathbb{R}^{2m \times m}$, and $C_T \in \mathbb{R}^{m \times 2m}$ are block diagonal matrices with diagonal blocks
\begin{equation}
A_{T,i} = \begin{bmatrix}
	0 & 1\\ -\frac{\alpha_0}{\alpha_2} & -\frac{\alpha_1}{\alpha_2}
\end{bmatrix}, \quad B_{T,i} = \begin{bmatrix}
	0 \\ \frac{\alpha_0}{\alpha_2}
\end{bmatrix}, \quad C_{T,i} = \begin{bmatrix}
	1 & 0
\end{bmatrix}.
\end{equation}

Derivatives of the adaptive parameters, used in (\ref{eq:esy_rd3}), (\ref{eq:eIy_rd3}), (\ref{eq:F3}), and (\ref{eq:u_rd3}), are given by
\begin{equation}
\begin{aligned}
	\dot{\hat{\Psi}}(t) &= (C_T^\delta X_{\hat{\Psi}})^T, \qquad \ddot{\hat{\Psi}}(t) &= (C_T^{\delta\delta}X_{\hat{\Psi}})^T \\
	\dot{\hat{\Theta}}(t) &= (C_T^\delta X_{\hat{\Theta}})^T, \qquad \ddot{\hat{\Theta}}(t) &= (C_T^{\delta\delta}X_{\hat{\Theta}})^T
\end{aligned} \label{eq:rd3-adaptation-deriv}
\end{equation}
where $C_T^{\delta}, C_T^{\delta \delta} \in \mathbb{R}^{m \times 2m}$ are block diagonal matrices with diagonals $C_{T,i}^{\delta} = \begin{bmatrix} 0,~ & 1	\end{bmatrix}$ and $C_{T,i}^{\delta\delta} = -\frac{1}{\alpha_2}\begin{bmatrix} \alpha_0,~ & \alpha_1 \end{bmatrix}$. For the plant (\ref{eq:plant_dynamics}) with second-order actuator model (\ref{eq:second_order_act}), an adaptive controller designed with reference model given by (\ref{eq:crm_mimo}), control input given by (\ref{eq:u_rd3}), and parameter adaptation given by (\ref{eq:rd3-adaptation-start})--(\ref{eq:rd3-adaptation-deriv}), asymptotic convergence of $e_y(t)$ to 0 is achieved.

\section{Human Supervisor}\label{subsec:sc_human}
%Notices, reacts, instructs.
We task the remote human supervisor with the following three responsibilities for shared anomaly response.
\begin{enumerate}[label=\textbf{Task \arabic*.}, leftmargin=1.8cm]
	\item Timely detection of anomalous closed-loop dynamical behavior
	\item Isolation and characterization of anomaly
	\item Commanding a change from nominal autopilot (\ref{eq:rd2-b1a})--(\ref{eq:rd2-adaptation}) to recovery autopilot (\ref{eq:rd3-b1a})--(\ref{eq:rd3-adaptation-deriv})
\end{enumerate}
The first task requires an attentive human operator able to discern that 
\begin{enumerate}[label=(\alph*)]
	\item an anomaly has occurred and control performance degradation is not caused solely by external disturbances;
	\item swift action must be taken in order to recover stability and performance;
	\item it may be possible to recover stability and performance via corrective action.
\end{enumerate}	
For the second task, the human operator must
\begin{enumerate}[label=(\alph*)]
	\item understand which control loop (e.g. pitch mode, roll mode, airspeed, in a fixed-wing UAV application) is affected by anomaly;
	\item perceive an increased lag in plant response to commands.
\end{enumerate}
%The second task requires a human operator with knowledge and familiarity with the plant dynamics and control structure to understand which control loop (e.g. pitch mode, roll mode, airspeed, in a fixed-wing UAV application) is the source of the anomalous dynamics. 
The final task for the trained remote human operator is the transfer of this diagnosis to the autopilot, by changing the relevant controller to its recovery mode.

%Note that while the remote human operator is assumed to have the training and controls necessary to disable all autopilot functionality and control the vehicle manually, this shared anomaly response deliberately circumvents any \textit{human-in-the-loop} (manual) control. 

\section{Overall Shared Controller}\label{subsec:sc_overall}
The shared control architecture between adaptive autopilots and a human operator that we propose is as follows. Before the occurrence of an anomaly, the nominal adaptive autopilot with control action defined in (\ref{eq:u_rd2}) is used to control the plant. An anomaly which abruptly changes actuator dynamics from (\ref{eq:first_order_act}) to (\ref{eq:second_order_act}) is assumed to occur at $t := t_1^*$. Following this time instant, the human operator is responsible for carrying out tasks 1--3 before the time limit at which failure would occur without action ($t:=t_3^*$). The completion of task 3 by the human ($t := t_2^*$) results in a switch to the recovery adaptive autopilot with control action as in (\ref{eq:u_rd3}). 

Note that our shared control architecture does not involve a handover of regulation and command tracking tasks to the human following an anomaly. Instead, in our shared control architecture, the human operator is responsible for high-level cognition tasks while adaptive autopilots retain responsibility for low-level regulation, therefore directly leveraging and combining their complementary merits.

\begin{figure}[h]
	\centering
	
\begin{tikzpicture}[auto, node distance=1.5cm,>=latex'] \scriptsize
    \node [align=center] (hp) at (0,0) {\Large Remote Human\\[2.5mm] \Large Operator};
    \node (p1) at (3.1,0) {\Large $+$};
    \node (ap) at (6.2,0) {\Large Autopilot};
    
    \node [row, below of = p1] (r1) {\Large $+$};
    \node [row, below of = r1] (r2) {\Large $+$};
    \node [row, below of = r2] (r3) {\Large $+$};
    \node [row, below of = r3] (r4) {\Large $+$};
    \node [row, below of = r4] (r5) {\Large $+$};
    \node [row, below of = r5] (r6) {\Large $+$};
    
    \node [stage, left of = r1] (s1) {\scriptsize Nominal\\\scriptsize Operation};
    \node [stage, left of = r2] (s2) {\scriptsize Information\\\scriptsize Acquisition};
    \node [stage, left of = r3] (s3) {\scriptsize Information\\\scriptsize Analysis};
    \node [stage, left of = r4] (s4) {\scriptsize Decision\\\scriptsize Selection};
    \node [stage, left of = r5] (s5) {\scriptsize Action\\\scriptsize Implementation};
    \node [stage, left of = r6] (s6) {\scriptsize Result};
    
	\node[star, fill=red, minimum width=0.4cm, inner sep=0pt, star points=5, star point ratio=2.25, draw] (anom) at (-5.3,-2.25) {};
	\node [right of = anom, node distance = 1.1cm] {\footnotesize $t = t_1^*$};
	
	\node[star, fill=green, minimum width=0.4cm, inner sep=0pt, star points=5, star point ratio=2.25, draw] (fix) at (-5.3,-8.25) {};
	\node [right of = fix, node distance = 1.1cm] {\footnotesize $t = t_2^*$};

    \draw [arr] ($(s1)+(0,1)$) -- (s1);
    \draw [arr] (s1) -- (s2);
    \draw [arr] (s2) -- (s3);
    \draw [arr] (s3) -- (s4);
    \draw [arr] (s4) -- (s5);
    \draw [arr] (s5) -- (s6);
    \draw [arr] (s6) -- ($(s6)+(0,-1)$);
        
	\node [note, below of = hp] (hp1) {\scriptsize Monitors for changes in\\\scriptsize autopilot performance};
	\node [note, below of = hp1] (hp2) {\scriptsize Primarily via visual sensing\\\scriptsize from displays};
	\node [note, below of = hp2] (hp3) {\scriptsize Internal models of vehicle dynamics, \\\scriptsize perceptive and cognitive capabilities};
	\node [note, below of = hp3] (hp4) {\scriptsize Chooses to switch autopilot to\\\scriptsize recovery mode, if appropriate};
	\node [note, below of = hp4] (hp5) {\scriptsize Communicates decision to autopilot\\\scriptsize through interface};
	\node [note, below of = hp5] (hp6) {\scriptsize Monitors to ensure performance \\\scriptsize improves and anomaly does not worsen};
	
	\node [note, below of = ap] (ap1) {\scriptsize Adaptive autopilot determines $u(t)$};
	\node [note, below of = ap1] (ap2) {\scriptsize Via vehicle sensors};
	\node [note, below of = ap2] (ap3) {\scriptsize Vehicle health monitoring algorithms\\\scriptsize such as innovations tests};
	\node [note, below of = ap3] (ap4) { };	
	\node [note, below of = ap4] (ap5) {\scriptsize Implements \textit{recovery} adaptive\\\scriptsize control algorithm};
	\node [note, below of = ap5] (ap6) {\scriptsize Adaptive autopilot determines $u(t)$};
\end{tikzpicture}

	\caption{Proposed framework for shared decision-making and control between a remote human operator and adaptive control algorithms following an anomaly, with roles organized by stages of decision making as categorized in Ref.~\cite{parasuraman2000model}}
	\label{fig:response_flow_remote}
\end{figure}
A detailed discussion of the stability of the closed-loop system with the overall shared controller is not carried out in this paper. But it is clear that if the human completes tasks 1--3 sufficiently fast (i.e., $t_2^* < t_3^*$), then the shared controller will guarantee boundedness of the closed-loop system and convergence of $e(t) = x(t) - x_m(t)$ to zero if our assumptions are satisfied. We carry out a detailed simulation study in the following chapter and evaluate the performance of the shared controller proposed above.
